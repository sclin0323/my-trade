{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一部分: Sequential 的逐層包裝與應用 - 以 CNN 圖形辨識模型為例\n",
    "\n",
    "手寫辨識模型將是今日作為範例的基本模型之一，我們一樣先從基本套件引用開始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 讀入套件、準備資料\n",
    "\n",
    "和之前的範例一樣，我們先將 Keras 內所需要的函數讀進來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras 相關套件/函數\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "\n",
    "# 資料庫\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀取 MNIST 資料庫\n",
    "\n",
    "一如之前的課程，在一開始，我們先讀取 MNIST 手寫辨識的資料庫，並進行資料格式上的整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x0_train, y0_train), (x0_test, y0_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做 CNN 的時候我們可以直接把矩陣塞進去。不過一張彩色的圖通常有 R, G, B 三個矩陣, 但我們這是灰階只有一個。所以 (28, 28) 的矩陣要變成\n",
    "\n",
    "* channels_last: (28, 28, 1)\n",
    "* channels_first: (1, 28, 28)\n",
    "\n",
    "注意，這相當惱人，因為不同 backend (TensorFlow, Theano, CNTK) 的表示法是不一樣的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x0_train.reshape(60000, 1, 28, 28)\n",
    "    x_test = x0_test.reshape(10000, 1, 28, 28)\n",
    "else:\n",
    "    x_train = x0_train.reshape(60000, 28, 28, 1)\n",
    "    x_test = x0_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y0_train, 10)\n",
    "y_test = np_utils.to_categorical(y0_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 打造 CNN\n",
    "\n",
    "我們使用和上次一樣的神經網路結構，但在每一個捲積層和全連接層，我們都使用指令 name= 來給定名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# convolution and then pooling\n",
    "model.add(Conv2D(10, (3, 3), padding='same', input_shape=(28,28,1), name='first_conv_layer'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# convolution and then pooling\n",
    "model.add(Conv2D(20, (3, 3), padding='same', name='second_conv_layer'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# convolution and then pooling\n",
    "model.add(Conv2D(120, (3, 3), padding='same', name='third_conv_layer'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flatten and connect with a fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, name='fc_layer_200'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# conneted with smaller fully connected layer\n",
    "# with the same number of neurons as the number of classes\n",
    "model.add(Dense(10, name='fc_layer_10'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_conv_layer (Conv2D)    (None, 28, 28, 10)        100       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "second_conv_layer (Conv2D)   (None, 14, 14, 20)        1820      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 20)          0         \n",
      "_________________________________________________________________\n",
      "third_conv_layer (Conv2D)    (None, 7, 7, 120)         21720     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 120)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1080)              0         \n",
      "_________________________________________________________________\n",
      "fc_layer_200 (Dense)         (None, 200)               216200    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "fc_layer_10 (Dense)          (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 241,850.0\n",
      "Trainable params: 241,850.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 重新打造 CNN\n",
    "\n",
    "## 其實，若神經網路的結構具有區塊性，我們可透過分段定義的方式來建立局部建立，以下是透過區塊定義的方式，設計和上面手寫辨識模型一樣結構的神經網路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) 首先，我們先將三層卷積層都用 list 包在一起。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer = [\n",
    "    # convolution and then pooling\n",
    "    Conv2D(10, (3, 3), padding='same', input_shape=(28,28,1), name='first_conv_layer'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # convolution and then pooling\n",
    "    Conv2D(20, (3, 3), padding='same', name='second_conv_layer'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # convolution and then pooling\n",
    "    Conv2D(120, (3, 3), padding='same', name='third_conv_layer'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將剩下兩個全連接層用 list 包在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_layer = [\n",
    "    # flatten and connect with a fully connected layer\n",
    "    Flatten(),\n",
    "    Dense(200, name='fc_layer_200'),\n",
    "    Activation('relu'),\n",
    "\n",
    "    # conneted with smaller fully connected layer\n",
    "    # with the same number of neurons as the number of classes\n",
    "    Dense(10, name='fc_layer_10'),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) 接著，用 Sequential 將兩個 list \"加\"起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_block_addition = Sequential(conv_layer + fc_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_block_addition.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提示: 可以用 .summary() 來比較 model 和 model_block_addition 的結構及權重數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_conv_layer (Conv2D)    (None, 28, 28, 10)        100       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "second_conv_layer (Conv2D)   (None, 14, 14, 20)        1820      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 20)          0         \n",
      "_________________________________________________________________\n",
      "third_conv_layer (Conv2D)    (None, 7, 7, 120)         21720     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 7, 120)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1080)              0         \n",
      "_________________________________________________________________\n",
      "fc_layer_200 (Dense)         (None, 200)               216200    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "fc_layer_10 (Dense)          (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 241,850.0\n",
      "Trainable params: 241,850.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_block_addition.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型局部的重複使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要注意到的是，新的手寫辨識模型有兩個區塊 conv_layer 和 fc_layer，若將 fc_layer 的神經元數量詳細寫出，我們將其表示為:\n",
    "　　　　\n",
    "<p><center>\n",
    "conv_layer -> (1080 -> 200 -> 10)\n",
    "</center></p>\n",
    "\n",
    "這樣的結構，可能有人可能會好奇，將模型改成\n",
    "\n",
    "<p><center>\n",
    "conv_layer -> 1080 -> 10\n",
    "</center></p>\n",
    "\n",
    "會不會就能得到一樣的效果，而我們又不想重新定義新的 conv_layer，此時，該如何做測試？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_single_layer = [\n",
    "    Flatten(),\n",
    "    Dense(10, name='fc_layer_10'),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2 = Sequential(conv_layer + fc_single_layer)\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_conv_layer (Conv2D)    (None, 28, 28, 10)        100       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "second_conv_layer (Conv2D)   (None, 14, 14, 20)        1820      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 20)          0         \n",
      "_________________________________________________________________\n",
      "third_conv_layer (Conv2D)    (None, 7, 7, 120)         21720     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 7, 120)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1080)              0         \n",
      "_________________________________________________________________\n",
      "fc_layer_10 (Dense)          (None, 10)                10810     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 34,450.0\n",
      "Trainable params: 34,450.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) 首先，我們先看看兩個模型在\"訓練前\"對測試資料的正確率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9760/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model_block_addition.evaluate(x_test, y_test)\n",
    "score_2 = model_2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始模型的正確率:  0.0977\n",
      "修改模型的正確率:  0.028\n"
     ]
    }
   ],
   "source": [
    "print(\"原始模型的正確率: \", score[1])\n",
    "print(\"修改模型的正確率: \", score_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) 再來，我們訓練原本的模型並查看其在測試資料上的正確率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 9s - loss: 0.3129 - acc: 0.9034     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f43b8548908>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_block_addition.fit(x_train, y_train, verbose=1, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9920/10000 [============================>.] - ETA: 0s\n",
      "原始模型的準確率:  0.9769\n"
     ]
    }
   ],
   "source": [
    "score = model_block_addition.evaluate(x_test, y_test)\n",
    "print(\"\")\n",
    "print(\"原始模型的準確率: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) 接著，在不訓練修改模型的情況下，直接看修改模型在測試資料上的正確率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s \n",
      "修改模型的準確率:  0.0829\n"
     ]
    }
   ],
   "source": [
    "score_2 = model_2.evaluate(x_test, y_test)\n",
    "print(\" \")\n",
    "print(\"修改模型的準確率: \", score_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### d) 現在反過來，先訓練修改模型並查看其在測試資料上的正確率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 8s - loss: 0.2594 - acc: 0.9306     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4394567b70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train, verbose=1, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9792/10000 [============================>.] - ETA: 0s修改模型的準確率:  0.9729\n"
     ]
    }
   ],
   "source": [
    "score_2 = model_2.evaluate(x_test, y_test)\n",
    "print(\"修改模型的準確率: \", score_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) 重新查看原始模型在測試資料上的正確率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9696/10000 [============================>.] - ETA: 0s原始模型的準確率:  0.9433\n"
     ]
    }
   ],
   "source": [
    "score = model_block_addition.evaluate(x_test, y_test)\n",
    "print(\"原始模型的準確率: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>世界為何變了?</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in conv_layer:\n",
    "    item.trainable = False\n",
    "    \n",
    "conv_layer[0].trainable\n",
    "#可以變更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二部分: `Model` functional API 的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們需要額外的兩個函數，分別是 `Model` 和 `Inout` 層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回憶之前模型的 summary ， output_shape 的改變是這樣的：\n",
    "\n",
    "<table border=\"0.1\">\n",
    "　<tr>\n",
    "　<td></td>\n",
    "　<td>C</td>\n",
    "  <td></td>\n",
    "　<td>P</td>\n",
    "  <td></td>\n",
    "　<td>C</td>\n",
    "  <td></td>\n",
    "　<td>P</td> \n",
    "  <td></td>\n",
    "　<td>C</td> \n",
    "  <td></td>\n",
    "　<td>P</td> \n",
    "  <td></td>\n",
    "　<td>F</td> \n",
    "   <td></td>\n",
    "　<td>D</td> \n",
    "   <td></td>\n",
    "  <td>D</td> \n",
    "  <td></td> \n",
    "　</tr>\n",
    "　<tr>\n",
    "　<td>28x28x1</td>\n",
    "　<td>-></td>\n",
    "  <td>28x28x10</td>\n",
    "　<td>-></td>\n",
    "  <td>14x14x10</td>\n",
    "　<td>-></td>\n",
    "  <td>14x14x20</td>\n",
    "　<td>-></td> \n",
    "  <td>7x7x20</td>\n",
    "　<td>-></td> \n",
    "  <td>7x7x120</td>\n",
    "　<td>-></td> \n",
    "  <td>3x3x120</td>  \n",
    "　<td>-></td> \n",
    "  <td>1080</td>\n",
    "　<td>-></td> \n",
    "   <td>200</td>\n",
    "　<td>-></td> \n",
    "   <td>10</td>\n",
    "　</tr>\n",
    "　<tr>\n",
    "　<td>$x$</td>\n",
    "　<td>-></td>\n",
    "  <td>$u_1$</td>\n",
    "　<td>-></td>\n",
    "  <td>$u_2$</td>\n",
    "　<td>-></td>\n",
    "  <td>$v_1$</td>\n",
    "　<td>-></td> \n",
    "  <td>$v_2$</td>\n",
    "　<td>-></td> \n",
    "  <td>$s_1$</td>\n",
    "　<td>-></td> \n",
    "  <td>$s_2$</td>  \n",
    "　<td>-></td> \n",
    "  <td>$d_1$</td>\n",
    "　<td>-></td> \n",
    "   <td>$d_2$</td>\n",
    "　<td>-></td> \n",
    "   <td>y</td>\n",
    "　</tr> \n",
    "</table>\n",
    "\n",
    "\n",
    "Functional API 的意思就是讓所有的層指令，看成像是函數作用在某個變數上一樣，在這裡，每一個神經網路層都視為函數並作用在前一層變數上，為了辨別出不同的層的差異，除了 `MaxPooling2D` 之外，我們都用一個函數名稱來標記，則表格如下：\n",
    "\n",
    "<table border=\"1\">\n",
    "　<tr>\n",
    "　<td></td>\n",
    "　<td>$f$</td>\n",
    "  <td></td>\n",
    "　<td>P</td>\n",
    "  <td></td>\n",
    "　<td>$g$</td>\n",
    "  <td></td>\n",
    "　<td>P</td> \n",
    "  <td></td>\n",
    "　<td>$h$</td> \n",
    "  <td></td>\n",
    "　<td>P</td> \n",
    "  <td></td>\n",
    "　<td>Flat</td> \n",
    "   <td></td>\n",
    "　<td>$\\alpha$</td> \n",
    "   <td></td>\n",
    "  <td>$\\beta$</td> \n",
    "  <td></td> \n",
    "　</tr>\n",
    "　<tr>\n",
    "　<td>28x28x1</td>\n",
    "　<td>-></td>\n",
    "  <td>28x28x10</td>\n",
    "　<td>-></td>\n",
    "  <td>14x14x10</td>\n",
    "　<td>-></td>\n",
    "  <td>14x14x20</td>\n",
    "　<td>-></td> \n",
    "  <td>7x7x20</td>\n",
    "　<td>-></td> \n",
    "  <td>7x7x120</td>\n",
    "　<td>-></td> \n",
    "  <td>3x3x120</td>  \n",
    "　<td>-></td> \n",
    "  <td>1080</td>\n",
    "　<td>-></td> \n",
    "   <td>200</td>\n",
    "　<td>-></td> \n",
    "   <td>10</td>\n",
    "　</tr>\n",
    "　<tr>\n",
    "　<td>$x$</td>\n",
    "　<td>-></td>\n",
    "  <td>$u_1$</td>\n",
    "　<td>-></td>\n",
    "  <td>$u_2$</td>\n",
    "　<td>-></td>\n",
    "  <td>$v_1$</td>\n",
    "　<td>-></td> \n",
    "  <td>$v_2$</td>\n",
    "　<td>-></td> \n",
    "  <td>$s_1$</td>\n",
    "　<td>-></td> \n",
    "  <td>$s_2$</td>  \n",
    "　<td>-></td> \n",
    "  <td>$d_1$</td>\n",
    "　<td>-></td> \n",
    "   <td>$d_2$</td>\n",
    "　<td>-></td> \n",
    "   <td>y</td>\n",
    "　</tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來，我們會使用 Model 建立和之前一樣的 CNN 手寫辨識模型，首先，是神經網路的輸入(Inout)，別忘記了， 輸入的資料大小為 28 x 28 x 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回憶一下手寫辨識模型的第一層是 \n",
    "\n",
    "<p><center>Conv2D(10, (3, 3), padding='same', input_shape=(28,28,1), name='first_conv_layer')</center></p>\n",
    "\n",
    "此時，第一層的 inpu_shape 將不被使用，此外，為了方便，我們將其 Activation 是 ReLu，我們將其合併在一起，寫成\n",
    "\n",
    "<p><center>Conv2D(10, (3, 3), padding='same', activation='relu', name='first_conv_layer')</center></p>\n",
    "\n",
    "\n",
    "Functional API 的意思就是讓所有的層指令，看成像是函數作用在某個變數上一樣，在這裡，`Conv2D(...)` 會作為一個函數，作用在變數 $x$ 上。為了方便起見，給 `Conv2D(...)` 一個好看的名字 $f$，並作用在 $x$ 上得到 $f(x)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = Conv2D(10, (3, 3), padding='same', activation='relu', name='first_conv_layer')\n",
    "u_1 = f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們剛剛處理的，是表格中的:\n",
    "\n",
    "<table border=\"1\">\n",
    "　<tr>\n",
    "　<td></td>\n",
    "　<td bgcolor=\"#FFFF00\">$f$</td>\n",
    "  <td></td>\n",
    "　<td>P</td>\n",
    "  <td></td>\n",
    "　<td>$g$</td>\n",
    "  <td></td>\n",
    "　<td>P</td> \n",
    "  <td></td>\n",
    "　<td>$h$</td> \n",
    "  <td></td>\n",
    "　<td>P</td> \n",
    "  <td></td>\n",
    "　<td>Flat</td> \n",
    "   <td></td>\n",
    "　<td>$\\alpha$</td> \n",
    "   <td></td>\n",
    "  <td>$\\beta$</td> \n",
    "  <td></td> \n",
    "　</tr>\n",
    "　<tr>\n",
    "　<td>28x28x1</td>\n",
    "　<td>-></td>\n",
    "  <td>28x28x10</td>\n",
    "　<td>-></td>\n",
    "  <td>14x14x10</td>\n",
    "　<td>-></td>\n",
    "  <td>14x14x20</td>\n",
    "　<td>-></td> \n",
    "  <td>7x7x20</td>\n",
    "　<td>-></td> \n",
    "  <td>7x7x120</td>\n",
    "　<td>-></td> \n",
    "  <td>3x3x120</td>  \n",
    "　<td>-></td> \n",
    "  <td>1080</td>\n",
    "　<td>-></td> \n",
    "   <td>200</td>\n",
    "　<td>-></td> \n",
    "   <td>10</td>\n",
    "　</tr>\n",
    "　<tr>\n",
    "　<td bgcolor=\"#FFFF00\">$x$</td>\n",
    "　<td bgcolor=\"#FFFF00\">-></td>\n",
    "  <td bgcolor=\"#FFFF00\">$u_1$</td>\n",
    "　<td>-></td>\n",
    "  <td>$u_2$</td>\n",
    "　<td>-></td>\n",
    "  <td>$v_1$</td>\n",
    "　<td>-></td> \n",
    "  <td>$v_2$</td>\n",
    "　<td>-></td> \n",
    "  <td>$s_1$</td>\n",
    "　<td>-></td> \n",
    "  <td>$s_2$</td>  \n",
    "　<td>-></td> \n",
    "  <td>$d_1$</td>\n",
    "　<td>-></td> \n",
    "   <td>$d_2$</td>\n",
    "　<td>-></td> \n",
    "   <td>y</td>\n",
    "　</tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著是 `MaxPooling` 的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = MaxPooling2D(pool_size=(2, 2))\n",
    "u_2 = P(u_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到，因為模型中所有的 `MaxPooling2D(pool_size=(2, 2))` 都長的一樣且不帶有參數，因此，定義過一次之後，就能重複使用。\n",
    "\n",
    "同上，我們已經處理完的部分是:\n",
    "\n",
    "<table border=\"1\">\n",
    "　<tr>\n",
    "　<td></td>\n",
    "　<td>f</td>\n",
    "  <td></td>\n",
    "　<td bgcolor=\"#FFFF00\">P</td>\n",
    "  <td></td>\n",
    "　<td>g</td>\n",
    "  <td></td>\n",
    "　<td>P</td> \n",
    "  <td></td>\n",
    "　<td>h</td> \n",
    "  <td></td>\n",
    "　<td>P</td> \n",
    "  <td></td>\n",
    "　<td>Flat</td> \n",
    "   <td></td>\n",
    "　<td>$\\alpha$</td> \n",
    "   <td></td>\n",
    "  <td>$\\beta$</td> \n",
    "  <td></td> \n",
    "　</tr>\n",
    "　<tr>\n",
    "　<td>28x28x1</td>\n",
    "　<td>-></td>\n",
    "  <td>28x28x10</td>\n",
    "　<td>-></td>\n",
    "  <td>14x14x10</td>\n",
    "　<td>-></td>\n",
    "  <td>14x14x20</td>\n",
    "　<td>-></td> \n",
    "  <td>7x7x20</td>\n",
    "　<td>-></td> \n",
    "  <td>7x7x120</td>\n",
    "　<td>-></td> \n",
    "  <td>3x3x120</td>  \n",
    "　<td>-></td> \n",
    "  <td>1080</td>\n",
    "　<td>-></td> \n",
    "   <td>200</td>\n",
    "　<td>-></td> \n",
    "   <td>10</td>\n",
    "　</tr>\n",
    "　<tr>\n",
    "　<td>$x$</td>\n",
    "　<td>-></td>\n",
    "  <td bgcolor=\"#FFFF00\">$u_1$</td>\n",
    "　<td bgcolor=\"#FFFF00\">-></td>\n",
    "  <td bgcolor=\"#FFFF00\">$u_2$</td>\n",
    "　<td>-></td>\n",
    "  <td>$v_1$</td>\n",
    "　<td>-></td> \n",
    "  <td>$v_2$</td>\n",
    "　<td>-></td> \n",
    "  <td>$s_1$</td>\n",
    "　<td>-></td> \n",
    "  <td>$s_2$</td>  \n",
    "　<td>-></td> \n",
    "  <td>$d_1$</td>\n",
    "　<td>-></td> \n",
    "   <td>$d_2$</td>\n",
    "　<td>-></td> \n",
    "   <td>y</td>\n",
    "　</tr> \n",
    "</table>\n",
    "剩下的部分依同樣的方式處理，則程式碼如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convolution+polling\n",
    "g = Conv2D(20, (3, 3), padding='same', activation='relu', name='second_conv_layer')\n",
    "v_1 = g(u_2)\n",
    "v_2 = P(v_1)\n",
    "\n",
    "\n",
    "h = Conv2D(120, (3, 3), padding='same', activation='relu', name='third_conv_layer')\n",
    "s_1 = h(v_2)\n",
    "s_2 = P(s_1)\n",
    "\n",
    "Flat = Flatten()\n",
    "d_1 = Flat(s_2)\n",
    "    \n",
    "alpha = Dense(200, activation='relu', name='fc_layer_200')\n",
    "d_2 = alpha(d_1)\n",
    "\n",
    "beta = Dense(10, activation='relu', name='fc_layer_10')\n",
    "y = beta(d_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，在 `Model` 指令中，將輸入 `x` 和輸出 `y` 指定，就可以構成一個模型了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_functional = Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "first_conv_layer (Conv2D)    (None, 28, 28, 10)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "second_conv_layer (Conv2D)   (None, 14, 14, 20)        1820      \n",
      "_________________________________________________________________\n",
      "third_conv_layer (Conv2D)    (None, 7, 7, 120)         21720     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1080)              0         \n",
      "_________________________________________________________________\n",
      "fc_layer_200 (Dense)         (None, 200)               216200    \n",
      "_________________________________________________________________\n",
      "fc_layer_10 (Dense)          (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 241,850.0\n",
      "Trainable params: 241,850.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_functional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三部分: Autoencoder 的介紹與 Submodel 的應用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們需要引進 `Reshape` layer，這個功能和 Numpy 的 reshape 很類似，只是是做為神經網路層來作用的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Reshape\n",
    "\n",
    "# 繪圖所需的運算函數\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_reshape = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test_reshape = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Autoencoder的建置與訓練: 在這個部分，我們將使用 `Model` 的寫法來撰寫 Autoencoder，並將 encoder 和 decoder 兩個子模型分別從原始模型中定義出來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#autoencoder:784->100->2->100->784\n",
    "x = Input(shape=(784, ))\n",
    "\n",
    "f = Dense(100, activation='sigmoid', name='hidden_layer_encoder')\n",
    "h_1 = f(x)\n",
    "\n",
    "encoder = Dense(2, activation='relu', name='representation_layer')\n",
    "encoded_x = encoder(h_1)\n",
    "\n",
    "g = Dense(100, activation='sigmoid', name='hidden_layer_decoder')\n",
    "h_2 = g(encoded_x)\n",
    "\n",
    "h = Dense(784, activation='sigmoid')\n",
    "x_reconstructed = h(h_2)\n",
    "\n",
    "#reshape_from_784_to_28x28x1 = Reshape((28, 28, 1))\n",
    "#x_reconstructed = reshape_from_784_to_28x28x1(deconded_h)\n",
    "\n",
    "autoencoder = Model(x, x_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_encoder (Dense) (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "representation_layer (Dense) (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "hidden_layer_decoder (Dense) (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               79184     \n",
      "=================================================================\n",
      "Total params: 158,186.0\n",
      "Trainable params: 158,186.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從 summary 可以看出除了一開始的 `Flatten` 和最後的 `Reshape`，Autoencoder 最主要的目的就是逐漸將原始資料壓縮，然後再反向的放大回來，並且希望最後得到的，和原本的檔案一樣。\n",
    "\n",
    "若能重建檔案，就代表中間的(壓縮 -> 還原)的過程，能保留檔案內(抽象)的重建資訊，因此，只需要紀錄檔案在神經網路中間的數值即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unsupervised learning\n",
    "autoencoder.compile(loss=\"binary_crossentropy\", optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.6897     \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.6653     \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.6427     \n",
      "Epoch 4/10\n",
      "11008/60000 [====>.........................] - ETA: 3s - loss: 0.6301"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train_reshape, x_train_reshape, verbose=1, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Encoder 子模型的定義及視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_reconstructed = autoencoder.predict(x_train_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_reconstructed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_reconstructed = x_train_reconstructed.reshape(60000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_test = np.random.randint(0,60000)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_train[no_test, :, :, 0], cmap='Greys')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(x_train_reconstructed[no_test], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "經過訓練後，我們可以看到圖片以及重建後的樣子，但我們關注的，並不是網路的輸出，而是其中間值，因此，我們定義一個小模型，使其輸出為原本 Autoencoder 的中間層，我們稱之為潛在特徵表示法 (latent feature representation)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = autoencoder.input\n",
    "reconstructed_img = autoencoder.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(x, encoded_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_encoded = encoder.predict(x_train_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display a 2D plot of the digit classes in the latent space\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_train_encoded[:, 0], x_train_encoded[:, 1], c=9-y0_train)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_encoded_small = encoder.predict(x_train_reshape[:1000])\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_train_encoded_small[:, 0], x_train_encoded_small[:, 1], c=9-y0_train[:1000])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，從某些不同數字的潛在特徵表示法，並沒有在空間上的關聯性，例如: 8 和 9 的潛在特徵表示法應該要很接近，而且介於兩者之間的潛在特徵表示，應該要與 8 和 9 相似，但從圖中發現，並沒有這樣的現象，也因此，我們需要在潛在特徵表示法上具有一些連續性的限制。\n",
    "\n",
    "為了檢驗上述的說法，我們視覺化 Autoencoder 的後半部，也就是 decoder 的部分，並將潛在特徵空間上進行均勻取樣並將結果貼在上面，用以檢視重建圖片的非連續性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Decoder 子模型的定義及視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(2,))\n",
    "_h_decoded = g(decoder_input)\n",
    "_x_decoded = h(_h_decoded)\n",
    "\n",
    "generator = Model(decoder_input, _x_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上面的程式碼，除了重新定義一個 2維的 Input 之外，剩下的函數都沿用 Autoencoder 已經定義過的層，這也是 Functional API 的精神所在，將任何運算都定義成函數的樣子去運作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display a 2D surface of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 神經網路沒有達到理想中的效果，該怎麼處理？\n",
    "* 增加/減少隱藏層的神經元數量\n",
    "* 增加隱藏層的數量，換句話說，就是改用 stacked Autoencoder\n",
    "* 改變訓練方式 e.g., SGD, Adagrad, rmsprop...\n",
    "* 改變權重的初始值\n",
    "* 加入 Dropout 結構\n",
    "* 層上面加入權重的限制式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四部分: Variational Autoencoder (VAE) 的介紹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這個部分，我們需要引進 `Lambda` layer 來客製化神經網路層，這是為了在 VAE 建立抽樣層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一開始，我們先把在這抽樣層之前的神經網路結構定義好，別忘記，在使用 `Model` 將神經網路的輸入輸出定義之前，這些變數都是自由的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(784, ))\n",
    "h = Dense(100, activation='relu', name='hidden_layer_encoder')(x)\n",
    "\n",
    "f = Dense(2, name='mean')\n",
    "z_mean = f(h)\n",
    "\n",
    "g = Dense(2, name='log_variance')\n",
    "z_log_var = g(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面 z_mean 和 z_log_var 代表的是多元常態分配的 Mean 和取對數後的 Variance (為何要取對數?)，將這兩者做為抽樣層的輸入，並希望抽樣出以上述資訊作為常態分配的抽樣母體；接著，我們來定義抽樣層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(2, ), mean=0., stddev=1)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用 `Lambda` 指令定義客製化層的時候，必須告訴對方吐出來的 tensor 大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(2, ), name='Normal_Sampleing')   ([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(100, activation='relu', name='hidden_layer_decoder')\n",
    "h_decoded = decoder_h(z)\n",
    "\n",
    "decoder_mean = Dense(784, activation='sigmoid', name='decoded_vector')\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "#reshape_from_784_to_28x28x1 = Reshape((28, 28, 1), name='decoded_image')\n",
    "#x_decoded = reshape_from_784_to_28x28x1(x_decoded_mean)\n",
    "\n",
    "vae = Model(x, x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到，VAE 的損失函數是檔案重建前後的 crossentropy，再加上中間的 (mean, var) 和 n維獨立標準常態分配的 KL-散度，因此，我們必須將中間的損失定出來，詳細定義如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decoded):\n",
    "    reconstruct_loss = 784 * K.binary_crossentropy(x, x_decoded)\n",
    "    \n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "                            , axis=-1)\n",
    "        \n",
    "    return reconstruct_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.compile(loss=vae_loss, optimizer=Adadelta())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了節省時間，我使用已經訓練好的模型權重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.load_weights('vae_MNIST_weights.h5')\n",
    "#vae.fit(x_train, x_train, shuffle=True, verbose=1, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同樣的，我們來看 VAE 的 endocer 部分:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test_reshape)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y0_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同樣的，我們也觀察看看 decoder 的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(2,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display a 2D surface of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
